# Chapitre 2 â€“ Ã‰quilibre de Nash : ThÃ©orie

# 2.1 Jeux stratÃ©giques (Strategic games)

Un **jeu stratÃ©gique** est un modÃ¨le pour des situations oÃ¹ plusieurs agents (*joueurs*) prennent des dÃ©cisions de maniÃ¨re indÃ©pendante et simultanÃ©e, chacun ayant un ensemble de stratÃ©gies possibles.

## DÃ©finition dâ€™un jeu stratÃ©gique

- Un ensemble de joueurs (au moins 2).
- Pour chaque joueur, un ensemble de **stratÃ©gies possibles**.
- Pour chaque combinaison de stratÃ©gies choisies, une **fonction de gain** (*payoff function*) pour chaque joueur.

### Notations usuelles

- **N** : nombre de joueurs.
- Pour chaque joueur *i*, $S_i$ est lâ€™ensemble de ses stratÃ©gies.
- $S = S_1 \times \ldots \times S_N$ : ensemble des profils de stratÃ©gies possibles.
- $u_i(s)$ : gain du joueur *i* quand le profil de stratÃ©gie $s \in S$ est jouÃ©.

---

## PrÃ©fÃ©rences ordinales

Des **prÃ©fÃ©rences ordinales** signifient que lâ€™on sait seulement **classer** les alternatives par ordre de prÃ©fÃ©rence, sans mesurer â€œcombienâ€ on prÃ©fÃ¨re lâ€™une Ã  lâ€™autre.

- On peut dire :  
  â€œJe prÃ©fÃ¨re A Ã  B, et B Ã  C.â€  
  Ou â€œJe suis indiffÃ©rent entre D et E.â€
- Mais on ne dit pas :  
  â€œJe prÃ©fÃ¨re A Ã  B deux fois plus que B Ã  C.â€ (cela serait cardinal, pas ordinal).

### Exemple dâ€™ordre ordinal

Supposons que les stratÃ©gies de Alice sont : {A, B, C}.  
Elle attribue la satisfaction suivante :
- $u(A) = 100$
- $u(B) = 10$
- $u(C) = 0$

Cela donne le mÃªme ordre ordinal que :
- $v(A) = 3$
- $v(B) = 2$
- $v(C) = 1$

Dans les deux cas, lâ€™ordre des prÃ©fÃ©rences est $A \succ B \succ C$ (A prÃ©fÃ©rÃ© Ã  B, B prÃ©fÃ©rÃ© Ã  C).  
**Ce qui compte, câ€™est lâ€™ordre, pas lâ€™Ã©cart entre les valeurs.**

---

> **RÃ©sumÃ©** :  
> Les prÃ©fÃ©rences ordinales permettent de classer les stratÃ©gies, sans tenir compte de lâ€™intensitÃ© de prÃ©fÃ©rence.  
> En thÃ©orie des jeux, lâ€™ordre suffit pour raisonner sur la rationalitÃ© et lâ€™Ã©quilibre.

##  2.2 Dilemme du Prisonnier â€“ Explication du tableau

|            | Quiet (S2)  | Fink (S2)   |
|:----------:|:-----------:|:-----------:|
| Quiet (S1) | 2 , 2       | 0 , 3       |
| Fink (S1)  | 3 , 0       | 1 , 1       |

- Chaque case montre les gains pour (Suspect 1, Suspect 2).
- "Quiet" = se taire (coopÃ©rer). "Fink" = dÃ©noncer (trahir).

**Lecture des cases**â€¯:  
- (Quiet, Quiet) â†’ 2,2 : petite peine pour chacun (coopÃ©ration)
- (Quiet, Fink) â†’ 0,3 : S1 prend tout, S2 est libÃ©rÃ©
- (Fink, Quiet) â†’ 3,0 : S1 est libÃ©rÃ©, S2 prend tout
- (Fink, Fink) â†’ 1,1 : chacun dÃ©nonce, peine moyenne

**InterprÃ©tation** :  
- Individuellement, chaque suspect a intÃ©rÃªt Ã  dÃ©noncer ("Fink").
- Mais si les deux dÃ©noncent, ils ont un rÃ©sultat moins bon que sâ€™ils avaient tous les deux coopÃ©rÃ©.

> **(Fink, Fink) = (1,1) est lâ€™Ã©quilibre de Nash du jeu.**
## Ex 16.1 : Jeu stratÃ©gique : Poissons hermaphrodites 

Deux poissons, chacun prÃ©fÃ¨re jouer le mÃªme rÃ´le lors de la reproduction (exâ€¯: "mÃ¢le").

### Actions possibles
- **Either** : Ãªtre flexible, accepter nâ€™importe quel rÃ´le
- **Insist** : insister sur son rÃ´le prÃ©fÃ©rÃ©

## Gains
- **H**â€¯: gain si jâ€™obtiens mon rÃ´le prÃ©fÃ©rÃ©
- **L**â€¯: gain si jâ€™ai lâ€™autre rÃ´le
- **S**â€¯: gain si pas de reproduction (je pars chercher ailleurs)

|               | Either (B)        | Insist (B)        |
|:-------------:|:----------------:|:----------------:|
| Either (A)    | Â½(H+L), Â½(H+L)   | L, H             |
| Insist (A)    | H, L             | S, S             |

- Si les deux sont flexibles, on tire au sort les rÃ´les
- Si un seul insiste, il obtient le rÃ´le voulu
- Si les deux insistent, ils ne sâ€™accouplent pas et partent

### Condition pour que le jeu soit un dilemme du prisonnier :
$$
H > \frac{1}{2}(H+L) > S > L
$$

C'est-Ã -dire :
- La tentation de "trahir" (insist) paie mieux si l'autre coopÃ¨re (either)
- La coopÃ©ration (deux "either") donne un gain intermÃ©diaire
- Si les deux trahissent (insistent), câ€™est pire que de coopÃ©rer, mais mieux que le pire rÃ´le

**lâ€™Ã©quilibre de Nash** est **(Insist, Insist)**â€¯:

> **Chaque poisson insiste sur son rÃ´le prÃ©fÃ©rÃ©, les deux repartent chercher ailleurs (chacun reÃ§oit S).**
# 2.3 Calcul dÃ©taillÃ© de lâ€™Ã©quilibre de Nash mixte â€” Bach ou Stravinsky

## Introduction

Dans "Bach ou Stravinsky", deux joueurs veulent aller ensemble Ã  un concert, mais lâ€™un prÃ©fÃ¨re Bach, lâ€™autre Stravinsky. Chacun prÃ©fÃ¨re Ãªtre avec lâ€™autre, mÃªme si ce nâ€™est pas Ã  son concert prÃ©fÃ©rÃ©.

On cherche ici lâ€™Ã©quilibre de Nash en **stratÃ©gies mixtes** (câ€™est-Ã -dire que chacun choisit "au hasard" selon une certaine probabilitÃ©).

# Calcul dÃ©taillÃ© de lâ€™Ã©quilibre mixte â€” Bach ou Stravinsky

## Ã‰tape 1 : Rappel du jeu

**Tableau des gains**

|                 | Bach (J2) | Stravinsky (J2) |
| :-------------: | :-------: | :-------------: |
| Bach (J1)       | 2 , 1     | 0 , 0           |
| Stravinsky (J1) | 0 , 0     | 1 , 2           |

- J1 prÃ©fÃ¨re Bach (gain max = 2), mais prÃ©fÃ¨re Ãªtre accompagnÃ©.
- J2 prÃ©fÃ¨re Stravinsky (gain max = 2), mais prÃ©fÃ¨re aussi Ãªtre accompagnÃ©.

---

## Ã‰tape 2 : StratÃ©gies mixtes

- Joueur 1 joue **Bach** avec proba p, **Stravinsky** avec 1â€¯â€“â€¯p.
- Joueur 2 joue **Bach** avec proba q, **Stravinsky** avec 1â€¯â€“â€¯q.

Chaque joueur choisit sa proba pour rendre l'autre **indiffÃ©rent** entre ses deux choix.

---

## Ã‰tape 3 : Calcul pour Joueur 1

**EspÃ©rance de gain pour J1 :**
- Si Bach : Eâ‚(Bach) = 2q
- Si Stravinsky : Eâ‚(Stravinsky) = 1â€¯â€“â€¯q

Pour qu'il randomise, il fautâ€¯:  
Eâ‚(Bach) = Eâ‚(Stravinsky)

Soit :  
2q = 1â€¯â€“â€¯q  
2q + q = 1  
3q = 1  
q = 1/3

**Donc J2 doit jouer Bach avec proba 1/3 pour rendre J1 indiffÃ©rent.**

---

## Ã‰tape 4 : Calcul pour Joueur 2

**EspÃ©rance de gain pour J2 :**
- Si Bach : Eâ‚‚(Bach) = p
- Si Stravinsky : Eâ‚‚(Stravinsky) = 2(1â€¯â€“â€¯p)

On Ã©galise :  
p = 2(1â€¯â€“â€¯p)  
p = 2â€¯â€“â€¯2p  
3p = 2  
p = 2/3

**Donc J1 doit jouer Bach avec proba 2/3 pour rendre J2 indiffÃ©rent.**

---

## Ã‰tape 5 : SynthÃ¨se du rÃ©sultat

Ã€ l'Ã©quilibre de Nash en stratÃ©gies mixtes :
- Joueur 1 joue Bach avec proba 2/3, Stravinsky avec 1/3
- Joueur 2 joue Bach avec proba 1/3, Stravinsky avec 2/3

---

## Explication importante

> Ã€ lâ€™Ã©quilibre de Nash en stratÃ©gies mixtes, chaque joueur choisit â€œau hasardâ€ selon une probabilitÃ© telle que lâ€™autre joueur nâ€™a aucune raison de changer sa propre rÃ©partition.
>
> Câ€™est parce que, pour chaque joueur, le gain moyen (espÃ©rance) obtenu en jouant lâ€™une ou lâ€™autre action est exactement le mÃªme, Ã©tant donnÃ© la faÃ§on dont lâ€™autre randomise.
# 2.4 Matching Pennies â€” Calcul de lâ€™Ã©quilibre de Nash

## Description du jeu

- **Deux joueurs.**
- Chacun choisit simultanÃ©ment pile (**P**) ou face (**F**).
- Si les deux choisissent la mÃªme face, Joueur 1 gagne (+1), Joueur 2 perd (â€“1).
- Si les faces sont diffÃ©rentes, Joueur 2 gagne (+1), Joueur 1 perd (â€“1).
- **Jeu Ã  somme nulle.**

---

## Matrice des gains

|            | P (J2)   | F (J2)   |
| :--------: | :------: | :------: |
| **P (J1)** |  1 , â€“1  | â€“1 , 1   |
| **F (J1)** | â€“1 , 1   |  1 , â€“1  |

---

## StratÃ©gies mixtes

- Joueur 1 joue Pile avec proba p, Face avec 1â€¯â€“â€¯p.
- Joueur 2 joue Pile avec proba q, Face avec 1â€¯â€“â€¯q.

---

## Calcul pour Joueur 1

**EspÃ©rance de gain si J1 joue Pile** :
Eâ‚(P) = q Ã— 1 + (1â€¯â€“â€¯q) Ã— (â€“1) = q â€“ (1â€¯â€“â€¯q) = 2q â€“ 1

**EspÃ©rance de gain si J1 joue Face** :
Eâ‚(F) = q Ã— (â€“1) + (1â€¯â€“â€¯q) Ã— 1 = â€“q + (1â€¯â€“â€¯q) = 1â€¯â€“â€¯2q

Ã€ lâ€™Ã©quilibre, J1 doit Ãªtre indiffÃ©rentâ€¯:
2qâ€¯â€“â€¯1 = 1â€¯â€“â€¯2q  
2qâ€¯â€“â€¯1 = 1â€¯â€“â€¯2q  
2q + 2q = 1 + 1  
4q = 2  
q = 1/2

**Donc J2 doit randomiser Pile/Face Ã  50%/50%.**

---

## Calcul pour Joueur 2

**EspÃ©rance de gain pour J2 si Pile** :
Eâ‚‚(P) = p Ã— (â€“1) + (1â€¯â€“â€¯p) Ã— 1 = â€“p + (1â€¯â€“â€¯p) = 1â€¯â€“â€¯2p

**EspÃ©rance de gain pour J2 si Face** :
Eâ‚‚(F) = p Ã— 1 + (1â€¯â€“â€¯p) Ã— (â€“1) = p â€“ (1â€¯â€“â€¯p) = 2p â€“ 1

On Ã©galise :
1â€¯â€“â€¯2p = 2pâ€¯â€“â€¯1  
1 + 1 = 2p + 2p  
2 = 4p  
p = 1/2

**Donc J1 doit randomiser Pile/Face Ã  50%/50%.**

---

## RÃ©sultat : Ã©quilibre de Nash

- Joueur 1 : Pile avec 1/2, Face avec 1/2.
- Joueur 2 : Pile avec 1/2, Face avec 1/2.

---

## Explication

- **Matching Pennies nâ€™a pas dâ€™Ã©quilibre de Nash en stratÃ©gies pures** (aucun couple (P,P), (F,F), (P,F), (F,P) nâ€™est stable).
- **Lâ€™unique Ã©quilibre de Nash est mixte** : chaque joueur joue au hasard avec 50%/50%.
- **Intuition** : si un joueur est prÃ©visible, lâ€™autre peut toujours le battre ; randomiser parfaitement rend toute stratÃ©gie de lâ€™autre indiffÃ©rente.

> Dans les jeux Ã  somme nulle simples comme Matching Pennies, lâ€™Ã©quilibre de Nash est toujours une stratÃ©gie mixte â€œpurement alÃ©atoireâ€.
## 2.5 stag hunt

- Il existe deux Ã©quilibres de Nash en stratÃ©gies pures dans le Stag Huntâ€¯:
    - (Stag, Stag)â€¯: gains 2,2 (optimal mais risquÃ©)
    - (Hare, Hare)â€¯: gains 1,1 (sÃ»r mais moins bon)
- Si un joueur doute ou "s'Ã©gare" (choisit Hare quand lâ€™autre choisit Stag), le chasseur qui restait sur le cerf obtient 0.
- AprÃ¨s une telle expÃ©rience, chacun prÃ©fÃ¨re la sÃ©curitÃ© du liÃ¨vreâ€¯: le groupe peut rester "bloquÃ©" sur lâ€™Ã©quilibre (Hare, Hare).
- **Le jeu illustre lâ€™importance de la confiance et de la coordination pour atteindre le meilleur rÃ©sultat collectif.**
- Choisir â€œHareâ€ (liÃ¨vre), câ€™est choisir la sÃ©curitÃ©â€¯: tu es sÃ»r de gagner 1, peu importe ce que fait lâ€™autre.
- Choisir â€œStagâ€ (cerf) est plus risquÃ©â€¯: tu gagnes plus (2) seulement si lâ€™autre choisit aussi â€œStagâ€, sinon tu gagnes 0.
- Si tu crains que lâ€™autre ne coopÃ¨re pas, ou si la confiance est faible, tu es poussÃ© Ã  choisir â€œHareâ€ pour tâ€™assurer un gain minimal garanti.
- Câ€™est pour Ã§a que â€œHareâ€ est dit â€œplus sÃ»râ€â€¯: pas de mauvaise surprise, pas de risque de repartir sans rien.
## 2.6 equilibre de nash # Ã‰quilibre de Nash â€” Explication dÃ©taillÃ©e selon Osborne

## ğŸ§© 1. Jeux stratÃ©giques : rappel du concept fondamental

Un **jeu stratÃ©gique** est une reprÃ©sentation formelle dâ€™une situation oÃ¹ plusieurs agents (joueurs) prennent simultanÃ©ment des dÃ©cisions, chacun cherchant Ã  maximiser son propre gain. Chaque joueur choisit sa stratÃ©gie sans connaÃ®tre les choix des autres joueurs.

Formellement, un jeu stratÃ©gique est dÃ©fini par :

- Un ensemble de joueurs : \( N = \{1, 2, \dots, n\} \)
- Pour chaque joueur \( i \), un ensemble de stratÃ©gies possibles \( S_i \)
- Pour chaque joueur \( i \), une fonction de gain (payoff) :
  \[
  u_i : S_1 \times S_2 \times \dots \times S_n \rightarrow \mathbb{R}
  \]

Chaque joueur \( i \) souhaite maximiser \( u_i \), son propre gain.

---

## ğŸ¯ 2. Meilleure rÃ©ponse : un concept central

La notion essentielle pour comprendre lâ€™Ã©quilibre de Nash est celle de **meilleure rÃ©ponse**.

La **meilleure rÃ©ponse** du joueur \( i \) Ã  un ensemble donnÃ© de stratÃ©gies des autres joueurs \( s_{-i} \) est la stratÃ©gie \( s_i^* \) qui lui donne le plus haut gain possible :

\[
u_i(s_i^*, s_{-i}) \geq u_i(s_i, s_{-i}) \quad\text{pour toute autre stratÃ©gie } s_i \in S_i
\]

Autrement dit :  
> Â« Si les autres choisissent leurs stratÃ©gies et ne changent pas, quelle stratÃ©gie me rapporte le plus ? Â»

---

##   DÃ©finition formelle de lâ€™Ã‰quilibre de Nash

Un **Ã©quilibre de Nash** est un profil de stratÃ©gies (câ€™est-Ã -dire un choix prÃ©cis pour chaque joueur) tel que **chaque joueur joue une meilleure rÃ©ponse aux choix des autres**.

Formellement, soit $s^* = (s_1^*, s_2^*, \dots, s_n^*)$ un profil de stratÃ©gies pour les $n$ joueurs.  
Ce profil est un Ã©quilibre de Nash si, pour chaque joueur $i$â€¯:

$$
u_i(s_i^*, s_{-i}^*) \geq u_i(s_i, s_{-i}^*) \quad \text{pour toute stratÃ©gie } s_i \in S_i
$$

Autrement ditâ€¯:

> *Aucun joueur ne peut amÃ©liorer son gain en changeant seul de stratÃ©gie, tant que les autres joueurs gardent leur choix.*

Un Ã©quilibre de Nash est donc un point de **stabilitÃ© stratÃ©gique**â€¯: chacun maximise son propre gain, Ã©tant donnÃ© ce que font les autres, et aucun nâ€™a intÃ©rÃªt Ã  dÃ©vier individuellement.


---

## ğŸ² 4. Exemples classiques en dÃ©tail (selon Osborne)

### ğŸ“ **Dilemme du prisonnier (Osborne 2.2)**

| Joueur 1 \ Joueur 2 | CoopÃ¨re (C) | Trahit (T) |
|---------------------|-------------|------------|
| CoopÃ¨re (C)         | 2 , 2       | 0 , 3      |
| Trahit (T)          | 3 , 0       | 1 , 1      |

Analyse dÃ©taillÃ©e :

- Si le joueur 2 coopÃ¨re, le joueur 1 prÃ©fÃ¨re trahir (gain 3 > 2).
- Si le joueur 2 trahit, le joueur 1 prÃ©fÃ¨re aussi trahir (gain 1 > 0).
- Â« Trahir Â» domine strictement Â« coopÃ©rer Â».

L'unique Ã©quilibre de Nash est donc : **(Trahit, Trahit)**.

Aucun joueur nâ€™a intÃ©rÃªt Ã  dÃ©vier seul (car il passerait de 1 Ã  0). Cependant, ce rÃ©sultat est collectivement sous-optimal (1,1 contre 2,2).

---

### ğŸ“ **Bach ou Stravinsky (Osborne 2.3)**

| Joueur 1 \ Joueur 2 | Bach (B) | Stravinsky (S) |
|---------------------|----------|----------------|
| Bach (B)            | 2 , 1    | 0 , 0          |
| Stravinsky (S)      | 0 , 0    | 1 , 2          |

Analyse dÃ©taillÃ©e :

- (Bach, Bach) : Joueur 1 gagne 2, Joueur 2 gagne 1. Personne n'a intÃ©rÃªt Ã  changer seul (ils passeraient tous deux Ã  0). Donc **(Bach, Bach)** est un Ã©quilibre de Nash.
- (Stravinsky, Stravinsky) : De mÃªme, chacun perdrait en changeant seul. Donc **(Stravinsky, Stravinsky)** est aussi un Ã©quilibre de Nash.
- Les autres profils (B,S) et (S,B) ne sont pas stables : chacun pourrait gagner en changeant.

Il y a donc deux Ã©quilibres de Nash distincts ici.

---

### ğŸ“ **Matching Pennies (Osborne 2.4)**

| Joueur 1 \ Joueur 2 | Pile (P) | Face (F) |
|---------------------|----------|----------|
| Pile (P)            | 1 , -1   | -1 , 1   |
| Face (F)            | -1 , 1   | 1 , -1   |

Analyse dÃ©taillÃ©e :

- Aucun Ã©quilibre en stratÃ©gies pures, car chaque profil incite toujours un joueur Ã  changer.
- Nash prouve que mÃªme dans ce cas, il existe toujours un Ã©quilibre en stratÃ©gies mixtes.
- Ici, l'Ã©quilibre mixte est que chaque joueur choisisse **Pile ou Face avec probabilitÃ© 1/2**, rendant lâ€™autre indiffÃ©rent Ã  son propre choix.

---

## ğŸ”‘ 5. PropriÃ©tÃ©s essentielles de lâ€™Ã©quilibre de Nash selon Osborne

- **Existence** : Nash (1950) montre que tout jeu stratÃ©gique fini possÃ¨de au moins un Ã©quilibre de Nash (en stratÃ©gies pures ou mixtes).
- **MultiplicitÃ©** : Certains jeux ont plusieurs Ã©quilibres de Nash.
- **StabilitÃ©** : Ã€ l'Ã©quilibre, personne ne peut amÃ©liorer sa situation en changeant unilatÃ©ralement.
- **Non optimalitÃ© collective** : Un Ã©quilibre de Nash nâ€™est pas forcÃ©ment le meilleur rÃ©sultat global pour lâ€™ensemble des joueurs (exemple typique : dilemme du prisonnier).

---

## ğŸ—¨ï¸ 6. InterprÃ©tation intuitive (selon Osborne)

Osborne insiste sur l'interprÃ©tation intuitive suivante :

- Un Ã©quilibre de Nash est un Ã©tat oÃ¹ les joueurs anticipent correctement les choix des autres joueurs.
- Chaque joueur joue une stratÃ©gie optimale (meilleure rÃ©ponse) par rapport Ã  ces anticipations.
- Ã€ l'Ã©quilibre, les anticipations se rÃ©alisent parfaitement : chacun anticipe correctement ce que font les autres.

Il s'agit d'une **situation auto-confirmante** :
> Â« Je fais ce que je fais parce que je prÃ©vois correctement les choix des autres joueurs, et ils font ce qu'ils font parce qu'ils prÃ©voient correctement les miens. Â»

---

## ğŸ“ 7. Citation directe dâ€™Osborne (traduction fidÃ¨le)

> Â« Un Ã©quilibre de Nash est un profil de stratÃ©gies oÃ¹ la stratÃ©gie de chaque joueur constitue une meilleure rÃ©ponse aux stratÃ©gies choisies par les autres joueurs. Ã€ l'Ã©quilibre, aucun joueur ne peut obtenir un gain supÃ©rieur en choisissant une autre stratÃ©gie, en supposant que les autres joueurs gardent inchangÃ©es leurs stratÃ©gies. Â»  
> *(Osborne, Chapitre 2.6)*

---

# 2.7 best response function 
# ğŸ¯ Fonction de meilleure rÃ©ponse (*Best Response Function*)

La notion de **fonction de meilleure rÃ©ponse** est fondamentale dans l'analyse des jeux stratÃ©giques. Elle joue un rÃ´le crucial dans la dÃ©finition et l'identification des Ã©quilibres de Nash.

---

## ğŸ“Œ DÃ©finition intuitive dÃ©taillÃ©e

La **meilleure rÃ©ponse** d'un joueur Ã  un ensemble donnÃ© de stratÃ©gies choisies par les autres joueurs est la stratÃ©gie qui lui offre le **meilleur gain possible**, en tenant compte du choix prÃ©cis des autres.

Autrement dit :  
> **Â« Compte tenu du choix exact des autres joueurs, quelle est la stratÃ©gie qui me rapporte le plus ? Â»**

C'est une maniÃ¨re de capturer la rationalitÃ© individuelle des joueurs face Ã  une situation stratÃ©gique.

---
## ## ğŸ“š DÃ©finition formelle complÃ¨te (selon Osborne)

Soit un jeu stratÃ©gique dÃ©fini parâ€¯:

- $N = \{1, 2, \dots, n\}$â€¯: l'ensemble des joueurs.
- Pour chaque joueur $i$, un ensemble de stratÃ©gies possibles $S_i$.
- Pour chaque joueur $i$, une fonction de gain (ou de paiement) :
  $$
  u_i(s_1, s_2, \dots, s_n)
  $$
  qui attribue un gain au joueur $i$ selon la combinaison de stratÃ©gies choisies par tous les joueurs.
    - $s_i$â€¯: la stratÃ©gie choisie par le joueur $i$.
    - $s_{-i}$â€¯: le profil des stratÃ©gies choisies par tous les autres joueurs (c'est-Ã -dire tous les $s_j$ pour $j \neq i$).

La **fonction de meilleure rÃ©ponse** du joueur $i$ aux stratÃ©gies $s_{-i}$ des autres joueurs est formellement dÃ©finie parâ€¯:

$$
B_i(s_{-i}) = \{\, s_i^* \in S_i\ |\ u_i(s_i^*, s_{-i}) \geq u_i(s_i, s_{-i}),\ \text{pour tout } s_i \in S_i \,\}
$$

Autrement dit, $B_i(s_{-i})$ est l'ensemble (parfois rÃ©duit Ã  une seule stratÃ©gie) des choix optimaux pour le joueur $i$, Ã©tant donnÃ© ce que font les autres joueurs.


---

## ## ğŸ² Exemple dÃ©taillÃ© : Dilemme du Prisonnier

ConsidÃ©rons le dilemme classique du prisonnier pour mieux comprendre :

| Joueur 1 \ Joueur 2 | CoopÃ¨re (C) | Trahit (T) |
|---------------------|-------------|------------|
| CoopÃ¨re (C)         | 2 , 2       | 0 , 3      |
| Trahit (T)          | 3 , 0       | 1 , 1      |

Analysons en dÃ©tail la fonction de meilleure rÃ©ponse de chaque joueur.

### ğŸ“ Pour le Joueur 1 :

- Si le Joueur 2 joue **CoopÃ¨re (C)** :
  - Joueur 1 gagne 2 s'il coopÃ¨re, 3 s'il trahit.
  - Donc, la meilleure rÃ©ponse Ã  Â« CoopÃ¨re Â» est **Trahir (T)**.

- Si le Joueur 2 joue **Trahir (T)** :
  - Joueur 1 gagne 0 s'il coopÃ¨re, 1 s'il trahit.
  - Donc, la meilleure rÃ©ponse Ã  Â« Trahir Â» est aussi **Trahir (T)**.

En notation formelle, on a donc :

- $B_1(\text{CoopÃ¨re}) = \{\text{Trahir}\}$  meilleur rÃ©ponse de J1 si J2 coopÃ¨re
- $B_1(\text{Trahir}) = \{\text{Trahir}\}$ meilleur rÃ©ponse de J1 si J2 trahis

RÃ©sumÃ© dans un tableau :

| Choix du joueur 2 | Meilleure rÃ©ponse du joueur 1 $B_1(\cdot)$ |
|-------------------|--------------------------------------------|
| CoopÃ¨re           | Trahir                                     |
| Trahir            | Trahir                                     |

En bref, $B_1(s_2)$ = Trahir pour tout $s_2$.

### ğŸ“ De mÃªme, pour le Joueur 2 (symÃ©triquement) :

- $B_2(\text{CoopÃ¨re}) = \{\text{Trahir}\}$
- $B_2(\text{Trahir}) = \{\text{Trahir}\}$

| Choix du joueur 1 | Meilleure rÃ©ponse du joueur 2 $B_2(\cdot)$ |
|-------------------|--------------------------------------------|
| CoopÃ¨re           | Trahir                                     |
| Trahir            | Trahir                                     |

Donc, $B_2(s_1)$ = Trahir pour tout $s_1$.

Ainsi, on obtient clairement que lâ€™Ã©quilibre de Nash est **(Trahir, Trahir)**,  
c'est-Ã -dire le seul profil $(s_1^*, s_2^*)$ oÃ¹ $s_1^* \in B_1(s_2^*)$ et $s_2^* \in B_2(s_1^*)$.


ğŸ² Exemple dÃ©taillÃ© : Dilemme du Prisonnier

ConsidÃ©rons le dilemme classique du prisonnier pour mieux comprendre :

| Joueur 1 \ Joueur 2 | CoopÃ¨re (C) | Trahit (T) |
|---------------------|-------------|------------|
| CoopÃ¨re (C)         | 2 , 2       | 0 , 3      |
| Trahit (T)          | 3 , 0       | 1 , 1      |

Analysons en dÃ©tail la fonction de meilleure rÃ©ponse de chaque joueur.

### ğŸ“ Pour le Joueur 1 :

- Si le Joueur 2 joue **CoopÃ¨re** :
  - Joueur 1 gagne 2 s'il coopÃ¨re, 3 s'il trahit.
  - Donc, la meilleure rÃ©ponse Ã  Â« CoopÃ¨re Â» est **Trahir**.

- Si le Joueur 2 joue **Trahir** :
  - Joueur 1 gagne 0 s'il coopÃ¨re, 1 s'il trahit.
  - Donc, la meilleure rÃ©ponse Ã  Â« Trahir Â» est aussi **Trahir**.

Ainsi, pour le Joueur 1, la fonction de meilleure rÃ©ponse est :

| Choix du joueur 2 | Meilleure rÃ©ponse du joueur 1 |
|-------------------|-------------------------------|
| CoopÃ¨re           | Trahir                        |
| Trahir            | Trahir                        |

En bref, le joueur 1 rÃ©pond toujours par **Trahir**.

### ğŸ“ De mÃªme, pour le Joueur 2 (symÃ©triquement) :

- Il rÃ©pond toujours par **Trahir**.

Ainsi, on obtient clairement lâ€™Ã©quilibre de Nash **(Trahir, Trahir)**.

---

## ğŸ“Š ReprÃ©sentation graphique ou conceptuelle (Best Response Function)

La fonction de meilleure rÃ©ponse peut aussi Ãªtre reprÃ©sentÃ©e graphiquement ou conceptuellement :
- **Axe horizontal**Â : stratÃ©gies possibles des autres joueurs ($s_{-i}$)
- **Axe vertical**Â : meilleure rÃ©ponse (stratÃ©gie optimale) du joueur Ã©tudiÃ© ($s_i^*$)

Un Ã©quilibre de Nash correspond alors Ã  lâ€™intersection simultanÃ©e des fonctions de meilleure rÃ©ponse de tous les joueurs.

---

## ğŸ”‘ Importance conceptuelle de la meilleure rÃ©ponse

Pourquoi cette notion est-elle si essentielle ?

- Elle permet de dÃ©terminer clairement les Ã©quilibres de Nash :
  - Un Ã©quilibre de Nash est prÃ©cisÃ©ment un point oÃ¹ **tous les joueurs choisissent simultanÃ©ment une meilleure rÃ©ponse aux choix des autres**.
- Elle illustre prÃ©cisÃ©ment le principe de rationalitÃ© individuelle :
  - Chaque joueur cherche toujours Ã  faire le meilleur choix possible face Ã  ce que font les autres joueurs.
- Elle clarifie les anticipations rationnelles :
  - La fonction de meilleure rÃ©ponse traduit lâ€™idÃ©e que les joueurs anticipent correctement les choix des autres pour dÃ©terminer leur propre stratÃ©gie optimale.

---
## 2.8.2 â€” Utilisation des fonctions de meilleure rÃ©ponse pour dÃ©finir lâ€™Ã©quilibre de Nash

Un **Ã©quilibre de Nash** est un profil dâ€™actions (câ€™est-Ã -dire un choix de stratÃ©gie pour chaque joueur) tel quâ€™aucun joueur ne peut obtenir un gain supÃ©rieur en modifiant unilatÃ©ralement sa propre action, les choix des autres restant inchangÃ©s.

En termes de **fonctions de meilleure rÃ©ponse**, on peut alors dire quâ€™un Ã©quilibre de Nash est un profil dans lequel **chaque joueur joue une meilleure rÃ©ponse aux actions des autres**.

**Proposition 34.1 â€” DÃ©finition Ã©quivalente de lâ€™Ã©quilibre de Nash**  
Soit $a^*$ un profil dâ€™actions. Alors $a^*$ est un Ã©quilibre de Nash si et seulement si, pour chaque joueur $i$ :
$$
a^*_i \in B_i(a^*_{-i})
$$
Câ€™est-Ã -dire : lâ€™action $a^*_i$ du joueur $i$ est une meilleure rÃ©ponse Ã  la combinaison des actions $a^*_{-i}$ des autres joueurs.

Si chaque joueur $i$ possÃ¨de une **unique** meilleure rÃ©ponse Ã  chaque choix des autres ($B_i(a_{-i}) = \{b_i(a_{-i})\}$), la condition prÃ©cÃ©dente devient simplement un systÃ¨me dâ€™Ã©quationsÂ :
$$
a^*_i = b_i(a^*_{-i}) \quad \text{pour chaque joueur } i
$$
Dans un jeu Ã  deux joueurs ($n=2$), ces Ã©quations sâ€™Ã©criventÂ :
$$
a^*_1 = b_1(a^*_2) \\
a^*_2 = b_2(a^*_1)
$$
Un profil $(a^*_1, a^*_2)$ est donc un Ã©quilibre de Nash si et seulement si :
- Lâ€™action de Joueur 1 est la meilleure rÃ©ponse Ã  lâ€™action de Joueur 2
- Lâ€™action de Joueur 2 est la meilleure rÃ©ponse Ã  lâ€™action de Joueur 1

---

## 2.8.3 â€” Utilisation des fonctions de meilleure rÃ©ponse pour trouver les Ã©quilibres de Nash

Cette dÃ©finition inspire une **mÃ©thode systÃ©matique** pour identifier les Ã©quilibres de Nash dans un jeu finiÂ :

1. **Trouver la fonction de meilleure rÃ©ponse de chaque joueur**Â : pour chaque combinaison des autres, dÃ©terminer la meilleure (ou les meilleures) action(s).
2. **Rechercher les profils qui satisfont simultanÃ©ment toutes les conditions ci-dessus** (câ€™est-Ã -dire, lÃ  oÃ¹ chaque joueur choisit effectivement une meilleure rÃ©ponse aux autres).

Si chaque joueur a une meilleure rÃ©ponse unique, il suffit de rÃ©soudre le systÃ¨me dâ€™Ã©quations ci-dessus. Sinon, il faut lister les profils oÃ¹ tous les joueurs choisissent une meilleure rÃ©ponse Ã  ce que font les autres.

---

## ğŸ“‹ **Exemple illustratif â€” Lecture dâ€™un tableau**

ConsidÃ©rons le jeu suivant (Figure 35.1)Â :

|       |    L    |    C    |    R    |
|-------|---------|---------|---------|
| **T** | 1, 2â˜…   | 2â˜…, 1   | 1â˜…, 0   |
| **M** | 2â˜…, 1â˜…  | 0, 1â˜…   | 0, 0    |
| **B** | 0, 1    | 0, 0    | 1â˜…, 2â˜…  |

- **Colonnes** : actions du Joueur 2 (L, C, R)
- **Lignes** : actions du Joueur 1 (T, M, B)
- **Premier nombre** : gain de Joueur 1
- **Second nombre** : gain de Joueur 2
- **â˜…** : meilleure rÃ©ponse pour le joueur concernÃ©

### Ã‰tapes pour trouver les Ã©quilibresÂ :

1. **Pour chaque colonne (L, C, R)**Â :  
   Chercher la meilleure rÃ©ponse de Joueur 1 (plus grand chiffre dans la colonne) â†’ mettre une â˜… Ã  cÃ´tÃ© du gain de J1.
2. **Pour chaque ligne (T, M, B)**Â :  
   Chercher la meilleure rÃ©ponse de Joueur 2 (plus grand chiffre dans la ligne) â†’ mettre une â˜… Ã  cÃ´tÃ© du gain de J2.
3. **Chercher les cases oÃ¹ les deux gains sont Ã©toilÃ©s**Â :
   - (M, L)Â : $2^\star, 1^\star$
   - (B, R)Â : $1^\star, 2^\star$

Chaque case doublement Ã©toilÃ©e correspond Ã  un **Ã©quilibre de Nash**.

---

### ğŸ“ RÃ©sumÃ© littÃ©raire

> La mÃ©thode des fonctions de meilleure rÃ©ponse permet dâ€™identifier visuellement les Ã©quilibres de NashÂ : ce sont exactement les cases du tableau oÃ¹ chaque joueur joue une meilleure rÃ©ponse Ã  lâ€™action de lâ€™autre. Ainsi, un Ã©quilibre de Nash, câ€™est un profil oÃ¹ chacun, connaissant le choix de lâ€™autre, nâ€™a rien Ã  gagner Ã  changer son propre choix.

## ğŸ² Exemple 37.1 â€” Une relation synergique (Osborne, Â§2.8)

Deux individus sont engagÃ©s dans une relation synergique.  
- Plus **chacun investit dâ€™effort** dans la relation, mieux ils se portent tous les deuxâ€¦ jusquâ€™Ã  un certain pointâ€¯:  
- Pour un effort de lâ€™autre fixÃ©, **le gain individuel augmente puis diminue** si on investit trop (effet "courbe en cloche").

### âš™ï¸ ModÃ©lisation du jeu

- **Joueurs :** deux individus (1 et 2)
- **Actions :** chaque joueur choisit un niveau dâ€™effort $a_i$ (nombre rÃ©el positif)
- **PrÃ©fÃ©rences :** pour chaque joueur $i$, le gain est donnÃ© par :
  
  $$
  u_i(a_i, a_j) = a_i \big(c + a_j - a_i\big)
  $$
  - $a_i$ : effort du joueur $i$
  - $a_j$ : effort de lâ€™autre joueur
  - $c$ : constante positive

---

### ğŸ” Analyse â€” Fonction de meilleure rÃ©ponse

Pour un effort de lâ€™autre joueur ($a_j$) fixÃ©, le gain $u_i$ est une fonction **quadratique** de $a_i$â€¯:  
- $u_i = a_i(c + a_j - a_i)$  
- Cette fonction vaut 0 pour $a_i = 0$ et pour $a_i = c + a_j$ (donc elle a un maximum entre les deux).

**Le maximum est obtenu pourâ€¯:**
$$
b_i(a_j) = \frac{1}{2}(c + a_j)
$$

*Si tu connais les dÃ©rivÃ©es, câ€™est juste la solution de $\frac{du_i}{da_i} = 0$.*

---

### ğŸ“ˆ Lecture graphique des fonctions de meilleure rÃ©ponse

- $b_1(a_2)$â€¯: meilleure rÃ©ponse de J1 Ã  chaque choix de $a_2$ (câ€™est une droite dans le plan $(a_1, a_2)$).
- $b_2(a_1)$â€¯: meilleure rÃ©ponse de J2 Ã  chaque $a_1$ (autre droite).

Pour lireÂ :
- **Choisis une valeur de $a_2$ (vertical)**, va Ã  la courbe $b_1$, descendsâ€¯: tu trouves $a_1 = b_1(a_2)$.
- **Choisis une valeur de $a_1$ (horizontal)**, va Ã  la courbe $b_2$, monteâ€¯: tu trouves $a_2 = b_2(a_1)$.

Un **Ã©quilibre de Nash** est un point $(a_1^*, a_2^*)$ oÃ¹ ces deux fonctions se coupent (intersection des deux droites) :
$$
a_1^* = b_1(a_2^*) \qquad\text{et}\qquad a_2^* = b_2(a_1^*)
$$

---

### ğŸ§® Calcul explicite de lâ€™Ã©quilibre de Nash

On a les deux Ã©quations suivantesÂ :
- $a_1^* = \frac{1}{2}(c + a_2^*)$
- $a_2^* = \frac{1}{2}(c + a_1^*)$

On remplace lâ€™une dans lâ€™autreÂ :

1. $a_1^* = \frac{1}{2}\left(c + \frac{1}{2}(c + a_1^*)\right)$  
2. $a_1^* = \frac{1}{2}(c + \frac{1}{2}c + \frac{1}{2}a_1^*)$  
3. $a_1^* = \frac{1}{2}c + \frac{1}{4}c + \frac{1}{4}a_1^*$  
4. $a_1^* - \frac{1}{4}a_1^* = \frac{3}{4}c$  
5. $\frac{3}{4}a_1^* = \frac{3}{4}c$  
6. $a_1^* = c$

Pareil pour $a_2^*$Â : $a_2^* = \frac{1}{2}(c + a_1^*) = \frac{1}{2}(c + c) = c$

Donc lâ€™**unique Ã©quilibre de Nash** estÂ :
$$
(a_1^*, a_2^*) = (c, c)
$$

---

### ğŸŒŸ Remarques et gÃ©nÃ©ralisation

- **UnicitÃ©** : Ici, il nâ€™y a **quâ€™un seul Ã©quilibre**, car les deux droites se croisent en un unique point.
- **Si la fonction de meilleure rÃ©ponse est "Ã©paisse"** (plusieurs meilleures rÃ©ponses possibles pour certains choix de lâ€™autre), il peut y avoir **une infinitÃ© dâ€™Ã©quilibres de Nash** (tous les points dâ€™intersection).
- **Graphiquement**, chaque intersection des deux courbes $b_1$ et $b_2$ correspond Ã  un Ã©quilibre de Nash.

---

### ğŸ“ RÃ©sumÃ©

- Quand chaque joueur a une meilleure rÃ©ponse unique Ã  chaque choix de lâ€™autre, il suffit de rÃ©soudre le systÃ¨meâ€¯:
  - $a_1^* = b_1(a_2^*)$
  - $a_2^* = b_2(a_1^*)$
- Ici, **lâ€™effort optimal est $c$ pour chaque joueur**.
- En gÃ©nÃ©ral, **chaque point dâ€™intersection des fonctions de meilleure rÃ©ponse** correspond Ã  un Ã©quilibre de Nash.

---

> **Ce type dâ€™exemple montre la puissance du formalisme des best responseÂ : on nâ€™a mÃªme pas besoin de tableau de jeu, il suffit dâ€™Ã©crire les fonctions et de chercher leurs points de croisement.**

# 2.8.4 Contribuer Ã  un bien publicâ€¯: explication dÃ©taillÃ©e et lecture graphique

## 1ï¸âƒ£ Le modÃ¨le

- Deux joueurs (personnes), chacun choisit combien $c_i$ il contribue Ã  un bien public (exÂ : propretÃ© dâ€™un parc).
- Plus la somme $c_1 + c_2$ est Ã©levÃ©e, plus chacun est satisfaitâ€¦ mais donner coÃ»te (Ã§a fait moins pour les â€œbiens privÃ©sâ€).
- Chaque joueur cherche Ã  maximiserÂ :  
  $u_i(c_1, c_2) = v_i(c_1 + c_2) - c_i$
    - $v_i$Â : utilitÃ© tirÃ©e du bien public, fonction â€œcourbe en clocheâ€ (monte puis descend)
    - $-c_i$Â : coÃ»t de la contribution

---

## 2ï¸âƒ£ Fonction de meilleure rÃ©ponse

- Pour un montant donnÃ© $c_2$ de lâ€™autre, **quelle contribution $c_1$ maximise mon bien-Ãªtreâ€¯?**
- Si lâ€™autre ne donne rien, mon â€œoptimumâ€ sâ€™appelle $b_1(0)$ (mÃªme chose pour J2 avec $b_2(0)$).
- Si lâ€™autre donne $k$, mon optimum estÂ : $b_1(k) = \max(b_1(0) - k, 0)$.
    - Donc, **plus lâ€™autre donne, moins je suis incitÃ© Ã  donner**.

---

## 3ï¸âƒ£ InterprÃ©tation du premier graphique (Figure 41.1)

- **Axe horizontalâ€¯:** montant donnÃ© par J1 ($c_1$)
- **Courbe $u_1(c_1, 0)$**â€¯: satisfaction de J1 quand J2 ne donne rien.
    - Monte jusquâ€™au maximum $b_1(0)$, puis descend (donner trop coÃ»te trop).
- **Courbe $u_1(c_1, k)$**â€¯: satisfaction de J1 quand J2 donne $k$.
    - **Câ€™est la courbe prÃ©cÃ©dente, dÃ©calÃ©e vers la gauche et vers le haut de $k$**.
    - Le maximum se trouve Ã  $b_1(k) = b_1(0) - k$ (sâ€™il reste positif).

**InterprÃ©tation**â€¯:  
> Plus lâ€™autre donne, moins je suis prÃªt Ã  donner pour obtenir le mÃªme â€œniveau de bien publicâ€.  
> Si lâ€™autre donne plus que ce que je voulais donner moi-mÃªme, ma meilleure rÃ©ponse devient zÃ©ro.

---

## 4ï¸âƒ£ InterprÃ©tation du deuxiÃ¨me graphique (Figure 42.1)

- **Axe horizontalâ€¯:** $c_1$ (contribution de J1)
- **Axe verticalâ€¯:** $c_2$ (contribution de J2)
- **Droite noire ($b_1(c_2)$)**â€¯: meilleure rÃ©ponse de J1 selon ce que fait J2 (pente â€“1, coupe lâ€™axe horizontal en $b_1(0)$)
- **Droite grise ($b_2(c_1)$)**â€¯: meilleure rÃ©ponse de J2 selon ce que fait J1 (pente â€“1, coupe lâ€™axe vertical en $b_2(0)$)

**Lâ€™Ã©quilibre de Nash correspond au(x) point(s) oÃ¹ ces deux droites se croisent**â€¯:

- Si $b_1(0) > b_2(0)$, lâ€™intersection est $(b_1(0), 0)$ (J1 donne tout, J2 rien)
- Si $b_2(0) > b_1(0)$, câ€™est $(0, b_2(0))$ (J2 donne tout, J1 rien)
- Si $b_1(0) = b_2(0)$, lâ€™intersection est tout le segment $c_1 + c_2 = b_1(0)$ (partage possible)

---

## 5ï¸âƒ£ Sens global et enseignement du modÃ¨le

- **Le jeu formalise le problÃ¨me du â€œpassager clandestinâ€ (free-rider problem)**Â : chacun espÃ¨re que lâ€™autre paiera la facture du bien collectif.
- **Ã€ lâ€™Ã©quilibre, seul le plus motivÃ© contribue**, sauf si les deux veulent donner exactement la mÃªme chose (cas rare).
- **Graphiquement**, tu peux toujours lire lâ€™Ã©quilibre de Nash comme **le point dâ€™intersection des courbes de meilleure rÃ©ponse**.

---

### âœï¸ RÃ©sumÃ©

- Plus lâ€™autre contribue, moins je contribue.
- Lâ€™Ã©quilibre de Nash est lÃ  oÃ¹ chacun fait la meilleure rÃ©ponse Ã  lâ€™autre (intersection des courbes).
- Dans ce modÃ¨le, **un seul joueur contribue**, lâ€™autre â€œprofiteâ€, sauf cas parfaitement symÃ©trique.
- - **Quand la droite de meilleure rÃ©ponse dâ€™un joueur coupe lâ€™axe horizontal ($c_2 = 0$),**  
  Ã§a veut dire que **Joueur 1 donne tout ce quâ€™il â€œveutâ€ donner, Joueur 2 ne donne rien**.
  - Point dâ€™Ã©quilibre : $(c_1^*, c_2^*) = (b_1(0), 0)$

- **Quand la droite de meilleure rÃ©ponse de lâ€™autre coupe lâ€™axe vertical ($c_1 = 0$),**  
  Ã§a veut dire que **Joueur 2 donne tout, Joueur 1 ne donne rien**.
  - Point dâ€™Ã©quilibre : $(c_1^*, c_2^*) = (0, b_2(0))$

- **Si les deux droites se croisent â€œau milieuâ€ (câ€™est rare),**  
  câ€™est quâ€™ils sont prÃªts Ã  donner exactement la mÃªme somme et  
  **toutes les rÃ©partitions oÃ¹ $c_1^* + c_2^* = b_1(0) = b_2(0)$ sont alors des Ã©quilibres**.

---

**En rÃ©sumÃ©**â€¯:
- **Croisement sur lâ€™axe horizontal**â€¯: seul le joueur 1 contribue, lâ€™autre rien.
- **Croisement sur lâ€™axe vertical**â€¯: seul le joueur 2 contribue, lâ€™autre rien.
- **Croisement â€œau milieuâ€**â€¯: les deux peuvent partager exactement la somme.


> Les deux graphiques montrent comment la stratÃ©gie de chacun sâ€™ajuste Ã  la gÃ©nÃ©rositÃ© de lâ€™autre, et pourquoi le financement des biens publics est souvent difficile sans coordination extÃ©rieure.

# 2.9 Actions dominÃ©es, domination stricte et faible

## 1. Domination stricte

- **IdÃ©e intuitiveâ€¯:**  
  Une action est **strictement dominÃ©e** si, peu importe ce que font les autres joueurs, il existe une autre action qui donne TOUJOURS un rÃ©sultat strictement meilleur.

### ğŸš¦ Exemples concrets

- Feu rouge, deux filesÂ :  
  La file de gauche (libre) **domine strictement** celle de droite (risque dâ€™Ãªtre bloquÃ© par un piÃ©ton ou une voiture qui tourne).  
  => Mieux dâ€™Ãªtre toujours Ã  gauche, peu importe ce que font les autres.

- **DÃ©finition formelle (Osborne)Â :**  
  Lâ€™action $a_i^{\prime}$ de joueur $i$ **domine strictement** $a_i$ si, pour toute combinaison $a_{-i}$ des autresÂ :
  $$
  u_i(a_i^{\prime}, a_{-i}) > u_i(a_i, a_{-i}) \quad \text{pour tout } a_{-i}
  $$

- **Dans le Dilemme du PrisonnierÂ :**  
  â€œTrahirâ€ (Fink) domine strictement â€œSe taireâ€ (Quiet)â€¯:  
  Peu importe ce que fait lâ€™autre, â€œTrahirâ€ rapporte toujours plus.

- **Effet sur lâ€™analyse des jeuxÂ :**  
  - **Une action strictement dominÃ©e ne sera jamais choisie dans un Ã©quilibre de Nash.**
  - On peut donc les **Ã©liminer du jeu** pour simplifier la recherche dâ€™Ã©quilibres.

- **Exemples du livre (Figure 44.1, gains de joueur 1)Â :**

|     | L | R |
|-----|---|---|
| T   | 1 | 0 |
| M   | 2 | 1 |
| B   | 1 | 3 |

Ici, M domine strictement T, mais B est parfois meilleur que M. T est strictement dominÃ©e et **ne peut pas apparaÃ®tre dans un Ã©quilibre**.

---

## 2. Domination faible

- **IdÃ©e intuitiveÂ :**  
  Une action est **faiblement dominÃ©e** si elle nâ€™est JAMAIS meilleure, et parfois pire, quâ€™une autre action.

- **Exemple concretÂ :**  
  Deux files au feu, une voiture dans chaqueÂ :  
  Si la voiture de droite ne tourne pas, les files sont Ã©quivalentesâ€¯;  
  si elle tourne, la file de gauche est meilleure.  
  => La file de gauche **faiblement domine** la droite.

- **DÃ©finition formelle (Osborne)Â :**  
  Lâ€™action $a_i^{\prime}$ de joueur $i$ **faiblement domine** $a_i$ siÂ :
  $$
  u_i(a_i^{\prime}, a_{-i}) \geq u_i(a_i, a_{-i}) \ \forall a_{-i},\quad \text{et strictement pour au moins un } a_{-i}
  $$

- **Effet sur lâ€™analyseÂ :**
  - Une action faiblement dominÃ©e **peut parfois apparaÃ®tre dans un Ã©quilibre de Nash non-strict** (mais jamais dans un Ã©quilibre strict).

---

## 3. Illustration et cas particuliers

- **Figure 45.1 (payoffs de joueur 1)**Â :

|     | L | R |
|-----|---|---|
| T   | 1 | 0 |
| M   | 2 | 0 |
| B   | 2 | 1 |

Ici,  
- M faiblement domine T,  
- B faiblement domine M,  
- B strictement domine T.

- **Conclusion du livreÂ :**
  - Toute action strictement dominÃ©e peut Ãªtre Ã©liminÃ©e, car aucun joueur rationnel ne la jouera.
  - Une action faiblement dominÃ©e nâ€™est JAMAIS jouÃ©e dans un Ã©quilibre strict, mais peut lâ€™Ãªtre dans un Ã©quilibre de Nash â€œordinaireâ€.

---

## 4. SynthÃ¨se

- **StratÃ©gie strictement dominÃ©e**Â : Jamais rationnelle, jamais choisie Ã  lâ€™Ã©quilibre.
- **StratÃ©gie faiblement dominÃ©e**Â : Pas optimale, mais parfois utilisÃ©e Ã  lâ€™Ã©quilibre si les autres actions ne sont pas strictement meilleures.

> **RÃ©sumÃ©Â :**  
> Ã‰liminer les stratÃ©gies strictement dominÃ©es simplifie la recherche dâ€™Ã©quilibre.  
> Les stratÃ©gies faiblement dominÃ©es demandent plus de prudence : elles peuvent parfois survivre dans les Ã©quilibres de Nash â€œnon strictsâ€.

---

## 2.10 Quâ€™est-ce quâ€™un Ã©quilibre symÃ©triqueâ€¯?

Un **Ã©quilibre symÃ©trique** est un Ã©quilibre de Nash dans lequel **tous les joueurs adoptent exactement la mÃªme stratÃ©gie**.

### ğŸ“Œ DÃ©finition formelle

- Un jeu est **symÃ©trique** si tous les joueurs ont le mÃªme ensemble dâ€™actions et la fonction de gain (payoff) est la mÃªme pour tous (quand on Ã©change les rÃ´les).
- Un **Ã©quilibre symÃ©trique** est alors un Ã©quilibre oÃ¹ **chaque joueur choisit la mÃªme action ou la mÃªme rÃ¨gle de choix (stratÃ©gie mixte)**.

### ğŸ§© Pourquoi câ€™est utileâ€¯?

- Cela rÃ©duit souvent le nombre de cas Ã  Ã©tudier (on cherche dâ€™abord les Ã©quilibres oÃ¹ tout le monde fait pareil).
- Beaucoup de jeux naturels (Dilemme du Prisonnier, Bataille des sexes, certains jeux de coordinationâ€¦) admettent des Ã©quilibres symÃ©triques, parfois en plus dâ€™autres Ã©quilibres.

### ğŸ“‹ Exemples

- **Dilemme du Prisonnier** :  
  Lâ€™Ã©quilibre (Trahir, Trahir) est **symÃ©trique** (les deux font la mÃªme chose).
- **Matching Pennies** :  
  Lâ€™Ã©quilibre mixte (Pile 1/2, Face 1/2) pour chaque joueur est **symÃ©trique**.
- **Bataille des Sexes (BoS)** :  
  Les Ã©quilibres purs (Bach, Bach) et (Stravinsky, Stravinsky) sont **symÃ©triques** si les prÃ©fÃ©rences sont identiques.

### âœï¸ Ã€ retenir

> Un **Ã©quilibre symÃ©trique**, câ€™est quand â€œtout le monde joue pareilâ€ dans un jeu oÃ¹ cela a un sens (mÃªmes rÃ¨gles, mÃªmes actions, mÃªmes prÃ©fÃ©rences).

---

**RÃ©sumÃ©**â€¯:  
- Ã‰quilibre symÃ©trique = chaque joueur adopte la mÃªme stratÃ©gie dans un Ã©quilibre de Nash.
- Ã‡a nâ€™existe que dans les jeux â€œsymÃ©triquesâ€ (mÃªmes actions et gains pour tous).

:(-------)
# Chapitre 4 : mixed strategies

# 4.1.1 â€” Ã‰tats stationnaires stochastiques (â€œStochastic steady statesâ€)

## ğŸ§© Contexte : que veut dire â€œÃ©tat stationnaireâ€ ?

- **Un Ã©quilibre de Nash** classique correspond Ã  une situation oÃ¹, si chaque joueur rÃ©pÃ¨te toujours la mÃªme action optimale, aucun nâ€™a intÃ©rÃªt Ã  changer seul.
- Cela modÃ©lise une situation â€œidÃ©aleâ€ oÃ¹, dans chaque rÃ´le de joueur, on a une **population** (groupe dâ€™individus possibles), et Ã  chaque partie, un individu est tirÃ© au hasard dans chaque population.
- **Dans un Ã©tat stationnaire** (steady state), les comportements restent constants dans le temps :  
  chaque joueur fait la mÃªme chose Ã  chaque partie, et nâ€™a aucune raison de changer car il connaÃ®t (par expÃ©rience) ce que font les autres.

---

## ğŸ”„ Ã‰tat stationnaire â€œpurâ€ et â€œmixteâ€

- **Ã‰tat stationnaire pur** :  
  Chacun joue **toujours la mÃªme action** (tout le monde se comporte pareil dans son groupe), donc chaque partie donne le mÃªme profil dâ€™Ã©quilibre de Nash.

- **Ã‰tats stationnaires plus gÃ©nÃ©raux**Â :  
  On permet que les joueurs ou les membres dâ€™une population **varient leur choix**, tant que la â€œrÃ©partition globaleâ€ reste constante.
    - Par exemple, une fraction $p$ des joueurs joue une action $a$.
    - Ou alors, chaque joueur tire **au hasard** son action selon une mÃªme loi de probabilitÃ© (mÃªme distribution chaque fois).

- **Ces deux visions sont Ã©quivalentes**Â :
    - Si dans une population, $p$ % des gens choisissent $a$, câ€™est mathÃ©matiquement pareil que si chaque individu choisit $a$ avec probabilitÃ© $p$.

---

## ğŸ² Lien avec lâ€™Ã©quilibre de Nash â€œmixteâ€

- **Un â€œmixed strategy Nash equilibriumâ€ (Ã©quilibre de Nash en stratÃ©gies mixtes)** modÃ©lise prÃ©cisÃ©ment ces Ã©tats stationnaires oÃ¹ les joueurs ne font pas toujours le mÃªme choix, mais gardent une distribution stable de comportements.
- En pratique, on retient surtout la vision â€œprobabilisteâ€Â :  
  chaque joueur joue chaque action possible **avec une certaine probabilitÃ© fixe**, Ã  chaque fois quâ€™il joue.

- **Un Ã©tat stationnaire stochastique** (â€œstochastic steady stateâ€) = situation oÃ¹, dans le temps, la rÃ©partition des choix reste stable, mÃªme si les choix individuels changent.

---

### ğŸ“ Ã€ retenir

> Un â€œÃ©tat stationnaire stochastiqueâ€, câ€™est un modÃ¨le oÃ¹ chaque joueur choisit ses actions au hasard, toujours selon la mÃªme loi de probabilitÃ©, et oÃ¹ ce â€œtirageâ€ forme un Ã©quilibre de Nash mixteÂ : aucun joueur nâ€™a intÃ©rÃªt Ã  changer sa faÃ§on de tirer au hasard.

---

**RÃ©sumÃ©**
- Ã‰tat stationnaire pur = chaque joueur joue toujours la mÃªme action.
- Ã‰tat stationnaire stochastique = chaque joueur joue chaque action selon une mÃªme probabilitÃ© fixe (stratÃ©gie mixte).
- Ces deux notions sont modÃ©lisÃ©es par les Ã©quilibres de Nash (purs ou mixtes).

## ğŸ² Exemple simple : Pierre-Feuille-Ciseaux

Prenons le jeu **Pierre-Feuille-Ciseaux** (Rock-Paper-Scissors), jouÃ© entre deux joueurs.

- **Tableau des gains** (gagnant = +1, perdant = â€“1, Ã©galitÃ© = 0) :

|             | Pierre | Feuille | Ciseaux |
|-------------|--------|---------|---------|
| **Pierre**  |  0,0   | â€“1,+1   | +1,â€“1   |
| **Feuille** | +1,â€“1  |  0,0    | â€“1,+1   |
| **Ciseaux** | â€“1,+1  | +1,â€“1   |  0,0    |

---

### ğŸŸ¢ **Ã‰tat stationnaire pur**

- Si chaque joueur **joue toujours Pierre**, alors chaque partie sera (Pierre, Pierre)â€¯:  
  câ€™est un Ã©tat stationnaire pur (mais ce nâ€™est pas un Ã©quilibre de Nash, car changer dâ€™action peut rapporter plus).

---

### ğŸ”„ **Ã‰tat stationnaire stochastique (stratÃ©gie mixte)**

- Supposons maintenant que **chaque joueur, Ã  chaque partie, choisit Pierre, Feuille ou Ciseaux avec proba 1/3**.
- Personne ne change sa â€œfaÃ§on de tirerâ€ (la distribution reste la mÃªme chaque fois).

- **RÃ©sultatâ€¯:**
    - Ã€ chaque partie, le rÃ©sultat est alÃ©atoire,  
      **mais la â€œrÃ©partition globaleâ€ (1/3, 1/3, 1/3)** reste stable dans le temps.
    - **Aucun joueur nâ€™a intÃ©rÃªt Ã  changer sa stratÃ©gie alÃ©atoire** (câ€™est un Ã©quilibre de Nash mixteâ€¯: si lâ€™autre joue 1/3â€“1/3â€“1/3, ta meilleure rÃ©ponse est aussi de randomiser Ã  1/3â€“1/3â€“1/3).

---

### ğŸ§  **InterprÃ©tation de la population**

- Imagine que, dans chaque rÃ´le, tu as toute une population de â€œjoueurs potentielsâ€â€¯: Ã  chaque partie, tu tires un joueur au hasard.
- **Si 1/3 de la population choisit Pierre, 1/3 Feuille, 1/3 Ciseaux**,  
  câ€™est exactement pareil que si chaque joueur individuel tire au hasard avec proba 1/3 chaque foisâ€¯:  
  la probabilitÃ© dâ€™obtenir Pierre face Ã  Ciseaux est la mÃªme.

---

### ğŸ“ Ã€ retenir

- **Ã‰tat stationnaire stochastique = Ã©quilibre de Nash mixte**
    - Les joueurs ne jouent pas toujours la mÃªme action, mais la **probabilitÃ©** de chaque action reste constante dans le temps.
    - Le systÃ¨me est stableâ€¯: si tu changes tes probabilitÃ©s seul, tu ne gagnes rien Ã  long terme.

---

### **Autres exemples**

- **Matching Pennies**â€¯: chaque joueur joue Pile ou Face avec proba 1/2, Ã  chaque tour.
- **En Ã©conomie**â€¯: chaque agent choisit dâ€™investir ou non dans un projet avec une certaine probabilitÃ©â€¯: tant que les proportions restent stables, câ€™est un Ã©tat stationnaire stochastique.

---

> **Conclusion**â€¯:  
> Un Ã©tat stationnaire stochastique, câ€™est quand, mÃªme si chaque individu varie son choix Ã  chaque partie,  
> **la â€œloi des grands nombresâ€ fait que la rÃ©partition globale reste la mÃªme**, et aucun nâ€™a intÃ©rÃªt Ã  changer ses habitudes probabilistes.

# 4.2 â€” Jeux stratÃ©giques oÃ¹ les joueurs peuvent randomiser

## ğŸ§© Pourquoi changer le modÃ¨le ?

- Avant (chap. 2), on supposait que chaque joueur choisit **une action â€œpureâ€** Ã  chaque partie.
- Pour modÃ©liser les **Ã©tats stationnaires stochastiques** (stratÃ©gies mixtes), il faut autoriser chaque joueur Ã  **randomiser ses choix** : choisir chaque action avec une certaine probabilitÃ©.

---

## ğŸŸ¢ Quâ€™est-ce quâ€™un jeu stratÃ©gique avec prÃ©fÃ©rences vNM ?

- On Ã©tend la dÃ©finition dâ€™un jeu stratÃ©giqueâ€¯:  
  Chaque joueur a des **prÃ©fÃ©rences sur des â€œloteriesâ€** (distributions de probabilitÃ©) sur les profils dâ€™action, et non plus juste sur les rÃ©sultats certains.
- Ces prÃ©fÃ©rences sont **reprÃ©sentÃ©es par lâ€™espÃ©rance mathÃ©matique dâ€™une fonction de gain dite â€œpayoff function de Bernoulliâ€**.
    - Câ€™est ce quâ€™on appelle une **prÃ©fÃ©rence vNM** (von Neumann-Morgenstern).

---

## ğŸ² Quâ€™est-ce que Ã§a change dans le tableau des gains ?

- Les tableaux (matrices) ressemblent Ã  ceux vus en chap. 2,  
  **mais les nombres dans chaque case ne sont plus seulement un â€œordre de prÃ©fÃ©renceâ€** (ordinal),  
  ce sont **des valeurs cardinales** qui reprÃ©sentent la â€œvaleurâ€ rÃ©elle de chaque issue ET de chaque loterie.
- **Exemple :**  
  Le gain pour â€œ(Q, Q)â€ nâ€™est plus seulement â€œmeilleur que (F, F)â€ â€”  
  il doit aussi permettre de calculer la valeur attendue dâ€™une loterie (exemple : 50% de (F, Q), 50% de (F, F)).

---

## ğŸ” Pourquoi deux tableaux â€œidentiquesâ€ au sens ordinal ne sont pas toujours Ã©quivalents en vNM ?

- **MÃªme ordre de prÃ©fÃ©rence** (ordinal) ne veut pas dire â€œmÃªme Ã©valuation des loteriesâ€ (cardinal).
- **Exemple dans le livre** (figure 104.1, Prisonerâ€™s Dilemma)â€¯:

|   | Q       | F       |
|---|---------|---------|
| Q | 2, 2    | 0, 3    |
| F | 3, 0    | 1, 1    |

|   | Q       | F       |
|---|---------|---------|
| Q | 3, 3    | 0, 4    |
| F | 4, 0    | 1, 1    |

- **Dans le tableau de gauche** :
    - Pour Joueur 1, le score de (Q, Q) = 2 = 0.5Ã—3 + 0.5Ã—1 = score attendu de la loterie [(F, Q), (F, F)] avec proba 50/50.
    - Donc J1 est indiffÃ©rent entre le rÃ©sultat sÃ»r (Q, Q) et la loterie.
- **Dans le tableau de droite** :
    - Pour Joueur 1, (Q, Q) = 3 > 0.5Ã—4 + 0.5Ã—1 = 2.5 (score attendu de la mÃªme loterie).
    - J1 prÃ©fÃ¨re donc le rÃ©sultat certain (Q, Q) Ã  la loterie.
- **Donc**â€¯: mÃªmes prÃ©fÃ©rences ordonnÃ©es, mais **pas la mÃªme attitude vis-Ã -vis du risque** (aversion, indiffÃ©rence, appÃ©tenceâ€¦).

---

## âœï¸ Ã€ retenir

- **Pour modÃ©liser des jeux oÃ¹ les joueurs peuvent randomiser leurs choix, il faut raisonner avec des prÃ©fÃ©rences vNM** (câ€™est-Ã -dire : prendre en compte la valeur attendue des gains).
- **Deux jeux â€œÃ©quivalentsâ€ ordinalement** peuvent Ãªtre **trÃ¨s diffÃ©rents** quand on autorise les stratÃ©gies mixtes.
- **La diffÃ©rence**â€¯: la â€œvaleurâ€ dâ€™une loterie dÃ©pend de la faÃ§on dont les scores (dans les cases) sont dÃ©finisâ€¯; ce nâ€™est pas quâ€™un simple classement.

---

> **RÃ©sumÃ©**â€¯:  
> Pour lâ€™Ã©tude des stratÃ©gies mixtes, il ne suffit plus de classer les issues â€œdu pire au meilleurâ€â€¯: il faut donner un sens Ã  la valeur attendue des loteries,  
> dâ€™oÃ¹ lâ€™importance des prÃ©fÃ©rences vNM et des â€œpayoff functionsâ€ de type cardinal.

